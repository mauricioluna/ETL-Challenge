{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eed09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Si se inspecciona el sitio Booking.com, uno se puede dar cuenta que las clases de los elementos de la página estan \n",
    "definidas por variables aleatorias de 10 caracteres, lo que genera bastantes problemas si uno quiere buscar un elemento \n",
    "determinado para realizar scrape. Además, se tienen instancias donde multiples clases definen un mismo objeto, lo\n",
    "que provoca un mayor tiempo de carga de la página y mayor dificultad en la lectura del HTML. \n",
    "\n",
    "Ahora bien, para obtener los objetos a los cuales se les quiere realizar scrape, se debe revisar el HTML mediante \n",
    "Inspeccionar elemento en un navegador (por ejemplo Chrome y Edge, basados en Chromium) e identificar las clases en \n",
    "HTML que definan un valor de texto determinado, como por ejemplo en el caso de Booking.com:\n",
    "        <div data-testid=\"title\" class=\"fcab3ed991 a23c043802\">Ruka Peumayen Caburgua</div>\n",
    "el cual define el nombre del hotel Ruka Peumayen Caburgua en la clase \"fcab3ed991 a23c043802\" y posee alias \"title\".\n",
    "'''\n",
    "\n",
    "'''\n",
    "Una forma en que se pueden realizar extracciones de esta pagina web es utilizando la libreria Scrapy para Python,\n",
    "la cual se puede instalar de diferentes formas siguiendo el tutorial disponible en https://docs.scrapy.org/en/latest/intro/install.html\n",
    "Sin embargo, tambien hay diferentes formas en las que se puede programar una extraccion usando Scrapy, siendo la forma más popular\n",
    "mediante la creacion de un proyecto Scrapy en una terminal (Powershell de Windows, Linux, o de Anaconda) por medio del\n",
    "comando:\n",
    "        scrapy startproject projectname #Linux\n",
    "        python -m scrapy startproject projectname #Terminal de Anaconda\n",
    "    \n",
    "El comando creará una carpeta projectname con archivos de Python predeterminados que serán utilizados por Scrapy, los cuales\n",
    "se deben editar en función de lo que uno requiere hacer.\n",
    "La otra forma de realizar la extraccion es directamente desde Jupyter Notebook sin tener que crear un proyecto de Scrapy.\n",
    "Esta ultima forma es la que será utilizada para definir la extracción de Booking.com en el siguiente notebook.\n",
    "\n",
    "Generalmente, en Scrapy uno debe definir una clase que crear un objeto Item, el cual permite guardar los datos no estructurados\n",
    "de una página web en un objeto estructurado con Fields definidos por Scrapy, los cuales pueden ser listas o diccionarios.\n",
    "Un ejemplo de Item y Fields en Scrapy es de la siguiente forma:\n",
    "'''\n",
    "import scrapy\n",
    "from scrapy.item import Item, Field\n",
    "class BookingItem(Item):\n",
    "    nombre = Field()\n",
    "    nota = Field()\n",
    "    lugar = Field()\n",
    "'''\n",
    "El cual define la clase BookingItem donde se guardaran los parametros nombre, nota y lugar, que significan el nombre de \n",
    "un Hotel, la calificación que tiene, y el lugar donde se encuentra, datos que serán extraidos de Booking.com directamente.\n",
    "Dado esto, se debe definir la clase que utiliza la \"araña\" de Scrapy, el cual es el objeto cuyo propósito es extraer los\n",
    "datos de una página web. Para el caso de Booking.com, se debe tomar en cuenta que la interfaz solo puede mostrar un máximo\n",
    "40 páginas con 25 hoteles cada una, por lo que una busqueda retorna máximo 1000 hoteles en total, agregando que en la URL de\n",
    "Booking.com luego de buscar un determinado hotel, además de ser innecesariamente larga, se pueden editar fácilmente los\n",
    "parámetros de busqueda lo que permite flexibilidad al querer hacer scrape a un conjunto de hoteles determinado.\n",
    "Otro problema de Booking.com es que solo se pueden ver los precios si se fija una fecha de entrada y una fecha de salida\n",
    "\n",
    "La clase Spider de Scrapy se puede definir de la siguiente forma:\n",
    "'''    \n",
    "class BookingSpider(scrapy.Spider):\n",
    "    name = \"booking\"\n",
    "    allowed_domains = [\"booking.com\"]\n",
    "    #Direccion(es) donde realizar web scraping\n",
    "    start_urls = ['https://www.booking.com/hotel/cl']\n",
    "    #Configuracion de pipelines\n",
    "    custom_settings = {\n",
    "    }\n",
    "    def parse(self, response):\n",
    "        for question in response.css(''):\n",
    "            item = BookingItem()\n",
    "            item['nombre'] = question.css('').extract_first()\n",
    "            item['nota'] = question.css('').extract_first()\n",
    "            item['lugar'] = question.css('').extract_first()\n",
    "            yield item\n",
    "'''\n",
    "Donde custom_settings es equivalente al archivo settings.py al realizarlo mediante la creación de un proyecto, en el\n",
    "se pueden editar los pipelines, que son parametros que definen, por ejemplo, como y donde guardar la base de datos además\n",
    "de datos adicionales para que el scrape sea correcto.\n",
    "La ultima parte de la función tambien se puede hacer mediante un diccionario en vez de un Item de Scrapy, quedando\n",
    "de la siguiente forma:\n",
    "'''\n",
    "def parse(self, response):\n",
    "        #Iterar en todos los objetos con la clase que define un hotel\n",
    "        for question in response.css(''):\n",
    "            yield{ \n",
    "            'nombre' : question.css('').extract_first(),\n",
    "            'nota' : question.css('').extract_first(),\n",
    "            'lugar' : question.css('').extract_first(),\n",
    "            }\n",
    "'''\n",
    "Es importante notar que response.css() (tambien puede ser response.xpath()) es denominado Selector en Scrapy, y es \n",
    "necesario para adquirir los datos en HTML y convertirlos a un formato reconocible por Python. Por ejemplo, para el HTML\n",
    "que define el nombre en el caso de Booking.com, su conversion a CSS queda de la siguiente forma:\n",
    "        <div data-testid=\"title\" class=\"fcab3ed991 a23c043802\">Ruka Peumayen Caburgua</div>\n",
    "        css->div.fcab3ed991.a23c043802\n",
    "Lo que implica que para buscar el nombre del hotel en el fragmento de codigo expuesto anteriormente, se debe escribir:\n",
    "        'nombre' : question.css('div.fcab3ed991.a23c043802::text').extract_first()\n",
    "el cual extrae el texto \"Ruka Peumayen Caburgua\" asignado a la clase \"fcab3ed991 a23c043802\".\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b86748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
